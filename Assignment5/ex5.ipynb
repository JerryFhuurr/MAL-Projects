{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)\n",
    "Y = (labels=='positive').astype(np.int_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the reviews and labels in test, train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reviews, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a CountVectorizer with a maximum of 10,000 most frequent words\n",
    "max_features = 10000\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "\n",
    "# Fit and transform the CountVectorizer on the training data\n",
    "X_train_bow = vectorizer.fit_transform(X_train[0])\n",
    "X_val_bow = vectorizer.transform(X_val[0])\n",
    "X_test_bow = vectorizer.transform(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore the representation of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_word(word_to_explore):\n",
    "    # Check if the word exists in the vocabulary\n",
    "    if word_to_explore in vectorizer.vocabulary_:\n",
    "        word_index = vectorizer.vocabulary_[word_to_explore]\n",
    "    \n",
    "        # Term frequency (TF) of the word \"movie\" in the training data\n",
    "        tf_movie = X_train_bow[:, word_index].toarray()\n",
    "    \n",
    "        # Count how many times \"movie\" appears in the training data\n",
    "        word_count = tf_movie.sum()\n",
    "    \n",
    "        # Print the results\n",
    "        print(f\"Index of '{word_to_explore}' in the vocabulary: {word_index}\")\n",
    "        print(f\"Term Frequency (TF) of '{word_to_explore}' in the training data: {tf_movie}\")\n",
    "        print(f\"Count of '{word_to_explore}' appearances in the training data: {word_count}\")\n",
    "    else:\n",
    "        print(f\"'{word_to_explore}' is not in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'movie' in the vocabulary: 5850\n",
      "Term Frequency (TF) of 'movie' in the training data: [[0]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [0]\n",
      " [7]\n",
      " [0]]\n",
      "Count of 'movie' appearances in the training data: 28015\n",
      "-----------------\n",
      "Index of 'excellent' in the vocabulary: 3097\n",
      "Term Frequency (TF) of 'excellent' in the training data: [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Count of 'excellent' appearances in the training data: 1325\n",
      "-----------------\n",
      "'oooooo' is not in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer with a maximum of 10,000 most frequent words\n",
    "max_features = 10000\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "\n",
    "# Fit and transform the CountVectorizer on the training data\n",
    "X_train_bow = vectorizer.fit_transform(X_train[0])\n",
    "\n",
    "# Assuming to explore the representation of the word\n",
    "explore_word(\"movie\")\n",
    "print(\"-----------------\")\n",
    "explore_word(\"excellent\")\n",
    "print(\"-----------------\")\n",
    "explore_word(\"oooooo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whole review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_whole_review(review):\n",
    "    # Use the CountVectorizer to transform the review into a BoW representation\n",
    "    review_bow = vectorizer.transform([review])\n",
    "\n",
    "    # Get the vocabulary (list of words) from the CountVectorizer\n",
    "    vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Extract the term frequencies (TF) from the BoW representation\n",
    "    tf_review = review_bow.toarray()[0]\n",
    "\n",
    "    # Print the BoW representation for the review\n",
    "    print(\"BoW Representation for the Review:\")\n",
    "    for word, tf in zip(vocabulary, tf_review):\n",
    "        if tf > 0:\n",
    "            print(f\"'{word}': {tf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation for the Review:\n",
      "'acting': 1\n",
      "'and': 1\n",
      "'excellent': 1\n",
      "'movie': 1\n",
      "'outstanding': 1\n",
      "'the': 2\n",
      "'was': 2\n",
      "--------------\n",
      "BoW Representation for the Review:\n",
      "'genre': 2\n",
      "'giant': 1\n",
      "'living': 1\n",
      "'monster': 1\n",
      "'movie': 2\n",
      "'mummy': 1\n",
      "'the': 2\n",
      "'with': 1\n"
     ]
    }
   ],
   "source": [
    "explore_whole_review(\"The movie was excellent, and the acting was outstanding.\")\n",
    "print('--------------')\n",
    "explore_whole_review(\"the giant monster movie genre with the living mummy movie genre .\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple neural network with one hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(10000,)),  \n",
    "    keras.layers.Dense(150, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on your training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.3574 - accuracy: 0.8497 - val_loss: 0.2827 - val_accuracy: 0.8878\n",
      "Epoch 2/8\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.1677 - accuracy: 0.9354 - val_loss: 0.3319 - val_accuracy: 0.8770\n",
      "Epoch 3/8\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0841 - accuracy: 0.9711 - val_loss: 0.3751 - val_accuracy: 0.8798\n",
      "Epoch 4/8\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 0.4475 - val_accuracy: 0.8777\n",
      "Epoch 5/8\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.4906 - val_accuracy: 0.8802\n",
      "Epoch 6/8\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.5349 - val_accuracy: 0.8755\n",
      "Epoch 7/8\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.5788 - val_accuracy: 0.8795\n",
      "Epoch 8/8\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.8785\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_bow.toarray(), Y_train, epochs=8, validation_data=(X_val_bow.toarray(), Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning and training, evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step\n",
      "Test Accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test_bow.toarray()) > 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the classifier to classify a few sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sentence: \"I loved the movie, it was amazing!\" => Predicted Sentiment: positive\n",
      "Sentence: \"The weather today is terrible.\" => Predicted Sentiment: positive\n",
      "Sentence: \"The food at that restaurant was outstanding.\" => Predicted Sentiment: positive\n",
      "Sentence: \"I'm feeling really sad today.\" => Predicted Sentiment: positive\n",
      "Sentence: \"The service was terrible, and I had a bad experience.\" => Predicted Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences to classify\n",
    "sample_sentences = [\n",
    "    \"I loved the movie, it was amazing!\",\n",
    "    \"The weather today is terrible.\",\n",
    "    \"The food at that restaurant was outstanding.\",\n",
    "    \"I'm feeling really sad today.\",\n",
    "    \"The service was terrible, and I had a bad experience.\",\n",
    "]\n",
    "\n",
    "sample_bow = vectorizer.transform(sample_sentences)\n",
    "\n",
    "# Make predictions using the classifier\n",
    "sample_predictions = (model.predict(sample_bow.toarray()) > 0.5).astype(int)\n",
    "\n",
    "# Display the results\n",
    "for sentence, prediction in zip(sample_sentences, sample_predictions):\n",
    "    sentiment = \"positive\" if prediction == 1 else \"negative\"\n",
    "    print(f'Sentence: \"{sentence}\" => Predicted Sentiment: {sentiment}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
